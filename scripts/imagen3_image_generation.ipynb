{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Imagen 3 Image Generation\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_image_generation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fimagen3_image_generation.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/imagen3_image_generation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_image_generation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1KDmM_PBAXz"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Katie Nguyen](https://github.com/katiemn) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkHPv2myT2cx"
   },
   "source": [
    "## Overview\n",
    "\n",
    "### Imagen 3\n",
    "\n",
    "Imagen 3 on Vertex AI brings Google's state of the art generative AI capabilities to application developers. Imagen 3 is Google's highest quality text-to-image model to date. It's capable of creating images with astonishing detail. Thus, developers have more control when building next-generation AI products that transform their imagination into high quality visual assets. Learn more about [Imagen on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/image/overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrkcqHrrwMAo"
   },
   "source": [
    "In this tutorial, you will learn how to use the Vertex AI SDK for Python to interact with the Imagen 3 and Imagen 3 Fast models to generate images showcasing:\n",
    "\n",
    "- Photorealistic scenes\n",
    "- Text rendered within images\n",
    "- Quality and latency comparisons within the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11Gu7qNgx1p"
   },
   "source": [
    "## Get started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XRvKdaPDTznN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"*******\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua6PDqB1iBSb"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yTiDo0lRh6sc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sr2Y3lFwKW1M"
   },
   "source": [
    "### Define a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r_38e5rRKB6s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_image(\n",
    "    image,\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "    if pil_image.mode != \"RGB\":\n",
    "        # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "        pil_image = pil_image.convert(\"RGB\")\n",
    "    image_width, image_height = pil_image.size\n",
    "    if max_width < image_width or max_height < image_height:\n",
    "        # Resize to display a smaller notebook image\n",
    "        pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "    IPython.display.display(pil_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLmwIj2RD0Fx"
   },
   "source": [
    "### Load the image generation models\n",
    "\n",
    "Imagen 3: `imagen-3.0-generate-001`\n",
    "\n",
    "Imagen 3 Fast: `imagen-3.0-fast-generate-001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "F-gd2ypQhh7K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-001\")\n",
    "generation_model_fast = ImageGenerationModel.from_pretrained(\n",
    "    \"imagen-3.0-fast-generate-001\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image for description 1...\n",
      "Image saved as genai_model_m_1.png\n",
      "Updated file after processing description 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m     generate_and_save_images(descriptions, txt_file_path, output_folder)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 72\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m descriptions \u001b[38;5;241m=\u001b[39m read_descriptions(txt_file_path)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Generate and save images\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mgenerate_and_save_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtxt_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 54\u001b[0m, in \u001b[0;36mgenerate_and_save_images\u001b[0;34m(descriptions, file_path, output_folder, base_name, separator)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated file after processing description \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Pause between generations to avoid overloading resources\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError generating image for description \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_descriptions(file_path, separator=\"-\" * 50):\n",
    "    \"\"\"\n",
    "    Reads descriptions from a file and splits them using the specified separator.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    return content.split(separator)\n",
    "\n",
    "def update_file(file_path, remaining_descriptions, separator=\"-\" * 50):\n",
    "    \"\"\"\n",
    "    Updates the file with the remaining descriptions.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(separator.join(remaining_descriptions))\n",
    "\n",
    "def generate_and_save_images(descriptions, file_path, output_folder, base_name=\"genai\", separator=\"-\" * 50):\n",
    "    \"\"\"\n",
    "    Generates images based on descriptions, saves them in the specified folder, and updates the text file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for i, prompt in enumerate(descriptions):\n",
    "        if not prompt.strip():  # Skip empty prompts\n",
    "            continue\n",
    "\n",
    "        print(f\"Generating image for description {i + 1}...\")\n",
    "        \n",
    "        try:\n",
    "            # Generate images with the model\n",
    "            image = generation_model.generate_images(\n",
    "                prompt=\"The painting depicts a rural scene at dusk or dawn.  A dirt road, muddy from recent rain, curves gently through the picture.  Bare, leafless trees line the road, their branches stark against a muted yellow-orange sky.  A woman, dressed in dark clothing and wearing a bonnet, walks along the road, away from the viewer.  In the background, a large stone wall runs alongside the road, culminating in a gated entrance to a large, stone building, possibly a manor house or estate. The overall atmosphere is tranquil and somewhat melancholic, with a focus on the muted colors and the solitary figure on the road.  The light suggests the time of day is either just before sunrise or just after sunset.\",\n",
    "                number_of_images=1,\n",
    "                aspect_ratio=\"3:4\",\n",
    "                safety_filter_level=\"block_some\",\n",
    "                person_generation=\"all_ages\",\n",
    "            )[0]._pil_image\n",
    "\n",
    "            # Save images with appropriate names\n",
    "            image_name = f\"{base_name}_model_m_{i + 1}.png\"\n",
    "            image.save(os.path.join(output_folder, image_name))\n",
    "            print(f\"Image saved as {image_name}\")\n",
    "\n",
    "            # Remove the processed description from the file only after successful generation\n",
    "            remaining_descriptions = descriptions[i + 1 :]  # Get all unprocessed descriptions\n",
    "            update_file(file_path, remaining_descriptions, separator)\n",
    "            print(f\"Updated file after processing description {i + 1}.\")\n",
    "\n",
    "            # Pause between generations to avoid overloading resources\n",
    "            time.sleep(30)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image for description {i + 1}: {e}\")\n",
    "            # Skip updating the file and move to the next description\n",
    "            continue\n",
    "\n",
    "def main():\n",
    "    # Path to the .txt file containing descriptions\n",
    "    txt_file_path = \"response_log.txt\"  # Update this to your actual file path\n",
    "\n",
    "    # Folder to save generated images\n",
    "    output_folder = \"fakeai\"\n",
    "\n",
    "    # Read descriptions\n",
    "    descriptions = read_descriptions(txt_file_path)\n",
    "\n",
    "    # Generate and save images\n",
    "    generate_and_save_images(descriptions, txt_file_path, output_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "imagen3_image_generation.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
